{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch wrapper for DFCSEN12MSDataset\n",
    "\n",
    "A DFCDataset object is created for the validation set by calling the constructor with the provided config values:\n",
    "- val_dir is passed as the base_dir to point to the validation data directory\n",
    "- val_mode is passed as 'test' to indicate this is the validation set\n",
    "- clip_sample_values is set to True to clip/limit the pixel values as specified\n",
    "- val_used_data_fraction of 1 means all validation data will be used\n",
    "- image_px_size is set to 224 for a 224x224 image size\n",
    "- cover_all_parts_validation is True, so a sliding window will be used to cover the entire validation image\n",
    "seed is set to 42 for reproducibility\n",
    "\n",
    "\n",
    "When initialized, the DFCDataset does the following main steps:\n",
    "- Sets up the seasons list to contain only 'Seasons.TESTSET' for the validation set\n",
    "- Reads in the validation observations CSV file from val_dir\n",
    "- Samples 100% of rows from the CSV based on val_used_data_fraction=1\n",
    "- No transforms are specified, so the default base transform (ToTensorV2) will be used\n",
    "\n",
    "\n",
    "When getitem is called to retrieve an item:\n",
    "- The observation for the index is retrieved from the DataFrame\n",
    "- The S1, S2, and LC data is loaded using the scene info\n",
    "- The data is clipped if clip_sample_values is True\n",
    "- A sliding window is used to cover the entire original image since cover_all_parts_validation is True\n",
    "- Only the base ToTensorV2 transform is applied\n",
    "- The data is normalized\n",
    "- A dict containing the transformed/normalized arrays is returned\n",
    "\n",
    "\n",
    "The validation DFCDataset will load the full validation data using a sliding window approach, clip values, apply a standard transform/normalization, and return the image/label tensors.\n",
    "\n",
    "\n",
    "The config allows control over the data sampling, transforms, normalizations etc. applied to the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dfc_dataset import DFCDataset\n",
    "\n",
    "# data_config = {\n",
    "#     'train_dir': 'data/data_disini', # path to the training directory,  \n",
    "#     'val_dir': 'data/data_disini', # path to the validation directory,\n",
    "#     'train_mode': 'validation', # can be one of the following: 'test', 'validation'\n",
    "#     'val_mode': 'test', # can be one of the following: 'test', 'validation'\n",
    "#     'num_classes': 8, # number of classes in the dataset.\n",
    "#     'clip_sample_values': True, # clip (limit) values\n",
    "#     'train_used_data_fraction': 1, # fraction of data to use, should be in the range [0, 1]\n",
    "#     'val_used_data_fraction': 1,\n",
    "#     'image_px_size': 224, # image size (224x224)\n",
    "#     'cover_all_parts_train': True, # if True, if image_px_size is not 224 during training, we use a random crop of the image\n",
    "#     'cover_all_parts_validation': True, # if True, if image_px_size is not 224 during validation, we use a non-overlapping sliding window to cover the entire image\n",
    "#     'seed': 42,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = DFCDataset(\n",
    "#     data_config['val_dir'],\n",
    "#     mode=data_config['val_mode'],\n",
    "#     clip_sample_values=data_config['clip_sample_values'],\n",
    "#     used_data_fraction=data_config['val_used_data_fraction'],\n",
    "#     image_px_size=data_config['image_px_size'],\n",
    "#     cover_all_parts=data_config['cover_all_parts_validation'],\n",
    "#     seed=data_config['seed'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/data_disini'\n",
    "mode = 'test'\n",
    "clip_sample_values = True\n",
    "used_data_fraction = 1\n",
    "image_px_size = 224\n",
    "cover_all_parts = True\n",
    "seed = 42\n",
    "\n",
    "# other parameter set to default\n",
    "transforms = None\n",
    "simclr_dataset = False\n",
    "balanced_classes = False\n",
    "sampling_seed = 42\n",
    "normalize = True\n",
    "moby_transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cover_all_parts: \n",
    "\n",
    "if image_px_size is not 224, this makes sure that during validation the entire image is used during training, we read image part at random parts of the original image, during vaildation, use a non-overlapping sliding window to cover the entire image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test [<Seasons.TESTSET: 'ROIs0000_test'>]\n"
     ]
    }
   ],
   "source": [
    "# from dfc_sen12ms_dataset import Seasons\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Seasons(Enum):\n",
    "    SPRING = \"ROIs1158_spring\"\n",
    "    SUMMER = \"ROIs1868_summer\"\n",
    "    FALL = \"ROIs1970_fall\"\n",
    "    WINTER = \"ROIs2017_winter\"\n",
    "    AUTUMN_DFC = \"ROIs0000_autumn\"\n",
    "    WINTER_DFC = \"ROIs0000_winter\"\n",
    "    SPRING_DFC = \"ROIs0000_spring\"\n",
    "    SUMMER_DFC = \"ROIs0000_summer\"\n",
    "    TESTSET = \"ROIs0000_test\"\n",
    "    VALSET = \"ROIs0000_validation\"\n",
    "    TEST = [TESTSET]\n",
    "    VALIDATION = [VALSET]\n",
    "    TRAIN = [SPRING, SUMMER, FALL, WINTER]\n",
    "    ALL = [SPRING, SUMMER, FALL, WINTER, VALIDATION, TEST]\n",
    "\n",
    "if mode == \"dfc\":\n",
    "    seasons = [\n",
    "        Seasons.AUTUMN_DFC,\n",
    "        Seasons.SPRING_DFC,\n",
    "        Seasons.SUMMER_DFC,\n",
    "        Seasons.WINTER_DFC,\n",
    "    ]\n",
    "elif mode == \"test\":\n",
    "    seasons = [Seasons.TESTSET]\n",
    "elif mode == \"validation\":\n",
    "    seasons = [Seasons.VALSET]\n",
    "elif mode == \"sen12ms\":\n",
    "    seasons = [\n",
    "        Seasons.SPRING,\n",
    "        Seasons.SUMMER,\n",
    "        Seasons.FALL,\n",
    "        Seasons.WINTER,\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Unsupported mode, must be in ['dfc', 'sen12ms', 'test', 'validation']\"\n",
    "    )\n",
    "\n",
    "print(mode, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_disini\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dfc_sen12ms_dataset.DFCSEN12MSDataset at 0x107f524c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dfc_sen12ms_dataset import DFCSEN12MSDataset\n",
    "\n",
    "print(base_dir)\n",
    "data = DFCSEN12MSDataset(base_dir)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(5128, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Scene</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season  Scene    ID\n",
       "0  Seasons.TESTSET      0  2014\n",
       "1  Seasons.TESTSET      0  3654\n",
       "2  Seasons.TESTSET      0  1101\n",
       "3  Seasons.TESTSET      0  3235\n",
       "4  Seasons.TESTSET      0   467"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if balanced_classes:\n",
    "    observations = pd.read_csv(\n",
    "        os.path.join(base_dir, mode + \"_observations_balanced_classes.csv\"),\n",
    "        header=0,\n",
    "        # names=[\"Season\", \"Scene\", \"ID\", \"dfc_label\", \"copy_nr\"],\n",
    "    )\n",
    "else:\n",
    "    observations = pd.read_csv(\n",
    "        os.path.join(base_dir, mode + \"_observations.csv\"),\n",
    "        header=None,\n",
    "        names=[\"Season\", \"Scene\", \"ID\"],\n",
    "    )\n",
    "print(balanced_classes)\n",
    "print(observations.shape)\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season\n",
      "Seasons.TESTSET    5128\n",
      "Name: count, dtype: int64\n",
      "Scene\n",
      "0    5128\n",
      "Name: count, dtype: int64\n",
      "ID\n",
      "2014    1\n",
      "2604    1\n",
      "385     1\n",
      "1144    1\n",
      "3611    1\n",
      "       ..\n",
      "1603    1\n",
      "2716    1\n",
      "3156    1\n",
      "704     1\n",
      "619     1\n",
      "Name: count, Length: 5128, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(observations['Season'].value_counts())\n",
    "print(observations['Scene'].value_counts())\n",
    "print(observations['ID'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 season, 1 scene & 5128 unique ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Scene</th>\n",
       "      <th>ID</th>\n",
       "      <th>ScenePart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>3654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>3235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season  Scene    ID  ScenePart\n",
       "0  Seasons.TESTSET      0  2014          0\n",
       "1  Seasons.TESTSET      0  3654          0\n",
       "2  Seasons.TESTSET      0  1101          0\n",
       "3  Seasons.TESTSET      0  3235          0\n",
       "4  Seasons.TESTSET      0   467          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cover_all_parts:\n",
    "    num_img_parts = int(256**2 / image_px_size**2)\n",
    "    obs = []\n",
    "    for season, scene, idx in observations.values:\n",
    "        for i in range(num_img_parts):\n",
    "            obs.append([season, scene, idx, i])\n",
    "\n",
    "    observations = pd.DataFrame(\n",
    "        obs, columns=[\"Season\", \"Scene\", \"ID\", \"ScenePart\"]\n",
    "    )\n",
    "print(cover_all_parts)\n",
    "print(image_px_size)\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_img_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_img_parts = int(256^2 / 224^2) computes to int(65536 / 50176), which is int(1.306...). When converted to an integer, this will result in num_img_parts being 1.\n",
    "\n",
    "This means that the loop for image parts will only iterate once (for i in range(1):), implying that each image is considered to be a single part of size 224x224.\n",
    "\n",
    "As a result, for each original observation, one entry will be added to the obs list. This entry represents the whole image (since 224x224 is almost the full area of a 256x256 image, with very little cropping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenePart\n",
       "0    5128\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[\"ScenePart\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagaimana kalo image_px_size kita turunkan angkanya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "112\n",
      "ScenePart\n",
      "0    5128\n",
      "1    5128\n",
      "2    5128\n",
      "3    5128\n",
      "4    5128\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Scene</th>\n",
       "      <th>ID</th>\n",
       "      <th>ScenePart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seasons.TESTSET</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season  Scene    ID  ScenePart\n",
       "0  Seasons.TESTSET      0  2014          0\n",
       "1  Seasons.TESTSET      0  2014          1\n",
       "2  Seasons.TESTSET      0  2014          2\n",
       "3  Seasons.TESTSET      0  2014          3\n",
       "4  Seasons.TESTSET      0  2014          4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percobaan(image_px_size=224):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if balanced_classes:\n",
    "        observations = pd.read_csv(\n",
    "            os.path.join(base_dir, mode + \"_observations_balanced_classes.csv\"),\n",
    "            header=0,\n",
    "            # names=[\"Season\", \"Scene\", \"ID\", \"dfc_label\", \"copy_nr\"],\n",
    "        )\n",
    "    else:\n",
    "        observations = pd.read_csv(\n",
    "            os.path.join(base_dir, mode + \"_observations.csv\"),\n",
    "            header=None,\n",
    "            names=[\"Season\", \"Scene\", \"ID\"],\n",
    "        )\n",
    "    print(balanced_classes)\n",
    "    \n",
    "    if cover_all_parts:\n",
    "        num_img_parts = int(256**2 / image_px_size**2)\n",
    "        obs = []\n",
    "        for season, scene, idx in observations.values:\n",
    "            for i in range(num_img_parts):\n",
    "                obs.append([season, scene, idx, i])\n",
    "\n",
    "        observations = pd.DataFrame(\n",
    "            obs, columns=[\"Season\", \"Scene\", \"ID\", \"ScenePart\"]\n",
    "        )\n",
    "    print(cover_all_parts)\n",
    "    print(image_px_size)\n",
    "    return observations\n",
    "\n",
    "observations_percobaan = percobaan(image_px_size=112)\n",
    "print(observations_percobaan['ScenePart'].value_counts())\n",
    "observations_percobaan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples 100% of rows from the CSV based on val_used_data_fraction=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 42\n",
      "(5128, 4)\n",
      "(5128, 4)\n"
     ]
    }
   ],
   "source": [
    "print(used_data_fraction, sampling_seed)\n",
    "print(observations.shape)\n",
    "observations = observations.sample(frac=used_data_fraction, random_state=sampling_seed).sort_index()\n",
    "print(observations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aradinka/miniforge3/envs/ssl/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from utils import AlbumentationsToTorchTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "print(transforms)\n",
    "base_aug = A.Compose([ToTensorV2()])\n",
    "base_transform = AlbumentationsToTorchTransform(base_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coba index 2\n",
    "idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasons.TESTSET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Season       Seasons.TESTSET\n",
       "Scene                      0\n",
       "ID                      1101\n",
       "ScenePart                  0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = observations.iloc[idx]\n",
    "\n",
    "class Seasons(Enum):\n",
    "    SPRING = \"ROIs1158_spring\"\n",
    "    SUMMER = \"ROIs1868_summer\"\n",
    "    FALL = \"ROIs1970_fall\"\n",
    "    WINTER = \"ROIs2017_winter\"\n",
    "    AUTUMN_DFC = \"ROIs0000_autumn\"\n",
    "    WINTER_DFC = \"ROIs0000_winter\"\n",
    "    SPRING_DFC = \"ROIs0000_spring\"\n",
    "    SUMMER_DFC = \"ROIs0000_summer\"\n",
    "    TESTSET = \"ROIs0000_test\"\n",
    "    VALSET = \"ROIs0000_validation\"\n",
    "    TEST = [TESTSET]\n",
    "    VALIDATION = [VALSET]\n",
    "    TRAIN = [SPRING, SUMMER, FALL, WINTER]\n",
    "    ALL = [SPRING, SUMMER, FALL, WINTER, VALIDATION, TEST]\n",
    "\n",
    "season = Seasons[obs.Season[len(\"Seasons.\") :]]\n",
    "\n",
    "print(season)\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 15 224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Window(col_off=22, row_off=15, width=224, height=224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rasterio.windows import Window\n",
    "\n",
    "if image_px_size != 256:\n",
    "    # crop the data to image_px_size times image_px_size (e.g. 128x128)\n",
    "    x_offset, y_offset = np.random.randint(0, 256 - image_px_size, 2)\n",
    "    window = Window(x_offset, y_offset, image_px_size, image_px_size)\n",
    "else:\n",
    "    window = None\n",
    "print(x_offset, y_offset, image_px_size)\n",
    "window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window is a rasterio class that defines a rectangular subset of a raster dataset in terms of row and column offsets and width and height in rows and columns.\n",
    "\n",
    "We creates a Window object with the offsets and dimensions specified by image_px_size. The Window specifies the rectangular region of the image to be cropped.\n",
    "\n",
    "If we set image_px_size to 224, the code would generate random x_offset and y_offset values between 0 and 32 (256 - 224 = 32). \n",
    "\n",
    "This would define the top-left corner of a 224x224 pixel window that the Window object represents. This window would be used to crop a 224x224 pixel region from a larger 256x256 pixel raster image. The purpose of this random offset is likely to introduce randomness in the cropping process, which can be a form of data augmentation or just a way to get different subsets of data from a larger image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1Bands(Enum):\n",
    "    VV = 1\n",
    "    VH = 2\n",
    "    ALL = [VV, VH]\n",
    "    NONE = None\n",
    "\n",
    "\n",
    "class S2Bands(Enum):\n",
    "    B01 = aerosol = 1\n",
    "    B02 = blue = 2\n",
    "    B03 = green = 3\n",
    "    B04 = red = 4\n",
    "    B05 = re1 = 5\n",
    "    B06 = re2 = 6\n",
    "    B07 = re3 = 7\n",
    "    B08 = nir1 = 8\n",
    "    B08A = nir2 = 9\n",
    "    B09 = vapor = 10\n",
    "    B10 = cirrus = 11\n",
    "    B11 = swir1 = 12\n",
    "    B12 = swir2 = 13\n",
    "    ALL = [B01, B02, B03, B04, B05, B06, B07, B08, B08A, B09, B10, B11, B12]\n",
    "    RGB = [B04, B03, B02]\n",
    "    NONE = None\n",
    "\n",
    "\n",
    "class LCBands(Enum):\n",
    "    LC = lc = 0\n",
    "    DFC = dfc = 1\n",
    "    ALL = [DFC]\n",
    "    NONE = None\n",
    "\n",
    "class Sensor(Enum):\n",
    "    s1 = \"s1\"\n",
    "    s2 = \"s2\"\n",
    "    lc = \"lc\"\n",
    "    dfc = \"dfc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Seasons.TESTSET: 'ROIs0000_test'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROIs0000_test'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seasons(season).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_bands=S2Bands.ALL\n",
    "\n",
    "# s1, s2, lc, bounds = [\n",
    "#     x.astype(np.float32) if type(x) == np.ndarray else x\n",
    "#     for x in data.get_s1_s2_lc_dfc_quad(\n",
    "#         season,\n",
    "#         obs.Scene,\n",
    "#         int(obs.ID),\n",
    "#         s1_bands=S1Bands.ALL,\n",
    "#         s2_bands=s2_bands,\n",
    "#         lc_bands=LCBands.LC,\n",
    "#         dfc_bands=LCBands.DFC,\n",
    "#         include_dfc=False,\n",
    "#         window=window,\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_disini/ROIs0000_test/s1_0/ROIs0000_test_s1_0_p1101.tif\n",
      "data/data_disini/ROIs0000_test/s2_0/ROIs0000_test_s2_0_p1101.tif\n",
      "data/data_disini/ROIs0000_test/lc_0/ROIs0000_test_lc_0_p1101.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "\n",
    "IGBP2DFC = np.array([0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 6, 8, 9, 10])\n",
    "\n",
    "def get_patch(season, scene_id, patch_id, bands, window=None):\n",
    "    \"\"\"\n",
    "        Returns raster data and image bounds for the defined bands of a specific patch\n",
    "        This method only loads a sinlge patch from a single sensor as defined by the bands specified\n",
    "    \"\"\"\n",
    "    season = Seasons(season).value\n",
    "    sensor = None\n",
    "\n",
    "    if not bands:\n",
    "        return None, None\n",
    "\n",
    "    if isinstance(bands, (list, tuple)):\n",
    "        b = bands[0]\n",
    "    else:\n",
    "        b = bands\n",
    "    \n",
    "    if isinstance(b, S1Bands):\n",
    "        sensor = Sensor.s1.value\n",
    "        bandEnum = S1Bands\n",
    "    elif isinstance(b, S2Bands):\n",
    "        sensor = Sensor.s2.value\n",
    "        bandEnum = S2Bands\n",
    "    elif isinstance(b, LCBands):\n",
    "        if LCBands(bands) == LCBands.LC:\n",
    "            sensor = Sensor.lc.value \n",
    "        else:\n",
    "            sensor = Sensor.dfc.value \n",
    "\n",
    "        bands = LCBands(1)\n",
    "        bandEnum = LCBands\n",
    "    else:\n",
    "        raise Exception(\"Invalid bands specified\")\n",
    "\n",
    "    if isinstance(bands, (list, tuple)):\n",
    "        bands = [b.value for b in bands]\n",
    "    else:\n",
    "        bands = bandEnum(bands).value\n",
    "\n",
    "    scene = \"{}_{}\".format(sensor, scene_id)\n",
    "    filename = \"{}_{}_p{}.tif\".format(season, scene, patch_id)\n",
    "    patch_path = os.path.join(base_dir, season, scene, filename)\n",
    "    print(patch_path)\n",
    "\n",
    "    with rasterio.open(patch_path) as patch:\n",
    "        if window is not None:\n",
    "            data = patch.read(bands, window=window) \n",
    "        else:\n",
    "            data = patch.read(bands)\n",
    "        bounds = patch.bounds\n",
    "\n",
    "    # Remap IGBP to DFC bands\n",
    "    if sensor  == \"lc\":\n",
    "        data = IGBP2DFC[data]\n",
    "\n",
    "    if len(data.shape) == 2:\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    return data, bounds\n",
    "\n",
    "s1, bounds1 = get_patch(season=season, scene_id=obs.Scene, patch_id=int(obs.ID), bands=S1Bands.ALL, window=window)\n",
    "s2, bounds2 = get_patch(season, scene_id=obs.Scene, patch_id=int(obs.ID), bands=S2Bands.ALL, window=window)\n",
    "lc, bounds3 = get_patch(season, scene_id=obs.Scene, patch_id=int(obs.ID), bands=LCBands.LC, window=window)\n",
    "\n",
    "bounds = next(filter(None, [bounds1, bounds2, bounds3]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        ...,\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6],\n",
       "        [6, 6, 6, ..., 6, 6, 6]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc[lc == 3] = 0\n",
    "lc[lc == 8] = 0\n",
    "lc[lc >= 3] -= 1\n",
    "lc[lc >= 8] -= 1\n",
    "lc -= 1\n",
    "\n",
    "# print(\"Number of invalid pixels:\", lc[lc == -1].size)\n",
    "lc[lc == -1] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        ...,\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] [50176]\n"
     ]
    }
   ],
   "source": [
    "lc_unique, lc_counts = np.unique(lc, return_counts=True)\n",
    "print(lc_unique, lc_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFC_map_clean = {\n",
    "    0: \"Forest\",\n",
    "    1: \"Shrubland\",\n",
    "    2: \"Grassland\",\n",
    "    3: \"Wetlands\",\n",
    "    4: \"Croplands\",\n",
    "    5: \"Urban/Built-up\",\n",
    "    6: \"Barren\",\n",
    "    7: \"Water\",\n",
    "    255: \"Invalid\",\n",
    "}\n",
    "\n",
    "lc_label = lc_unique[\n",
    "    lc_counts.argmax()\n",
    "]  # this is already mapped to dfc in data.get_s1_s2_lc_dfc_quad\n",
    "lc_label_str = DFC_map_clean[int(lc_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Croplands\n"
     ]
    }
   ],
   "source": [
    "print(lc_label, lc_label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lc_multilabel = torch.tensor(\n",
    "    [\n",
    "        class_idx\n",
    "        for class_idx, num in zip(lc_unique, lc_counts)\n",
    "        if num / image_px_size**2 >= 0.1 and class_idx != 255\n",
    "    ]\n",
    ").long()\n",
    "lc_multilabel_one_hot = torch.nn.functional.one_hot(\n",
    "    lc_multilabel.flatten(), num_classes=8\n",
    ").float()\n",
    "lc_multilabel_one_hot = lc_multilabel_one_hot.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_multilabel_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(clip_sample_values)\n",
    "if clip_sample_values:\n",
    "    s1 = np.clip(s1, a_min=-25, a_max=0)\n",
    "    s1 = (\n",
    "        s1 + 25\n",
    "    )  # go from [-25,0] to [0,25] interval to make normalization easier\n",
    "    s2 = np.clip(s2, a_min=0, a_max=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.02639401,  9.78071514, 10.13958169, ..., 11.13204785,\n",
       "         10.49177439, 11.37512439],\n",
       "        [10.71481945,  9.88525474,  9.2328549 , ..., 10.48376037,\n",
       "         10.79516637, 11.75380497],\n",
       "        [10.92238227, 10.84129933,  9.19645813, ..., 10.61944233,\n",
       "         10.50448479, 11.16301832],\n",
       "        ...,\n",
       "        [ 9.52744245,  9.67639517,  9.89710906, ...,  9.5774624 ,\n",
       "         10.12303341, 10.31890257],\n",
       "        [ 9.53173707, 10.2359588 ,  9.76507098, ..., 10.12211425,\n",
       "         10.66147032, 10.8344312 ],\n",
       "        [10.28666748,  9.97718324, 10.86651068, ...,  9.81332924,\n",
       "         10.48862606, 11.14928442]],\n",
       "\n",
       "       [[ 4.0022885 ,  5.46716512,  6.54422221, ...,  5.26850347,\n",
       "          4.57792922,  5.76102369],\n",
       "        [ 5.24813458,  5.01389379,  5.43050958, ...,  3.70929459,\n",
       "          4.72105449,  5.34384327],\n",
       "        [ 5.06700391,  6.88751629,  4.68191418, ...,  4.53374084,\n",
       "          4.98471528,  5.67624763],\n",
       "        ...,\n",
       "        [ 3.83213516,  3.93717569,  5.4616625 , ...,  4.51561371,\n",
       "          4.3101618 ,  5.31069308],\n",
       "        [ 3.79882298,  4.48278241,  3.70541477, ...,  3.93796965,\n",
       "          5.20303723,  4.67224232],\n",
       "        [ 2.40133955,  3.0791948 ,  2.53815966, ...,  3.56606902,\n",
       "          4.07896755,  4.21574313]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1467., 1671., 1671., ..., 1397., 1397., 1397.],\n",
       "        [1467., 1671., 1671., ..., 1397., 1397., 1397.],\n",
       "        [1467., 1671., 1671., ..., 1397., 1397., 1397.],\n",
       "        ...,\n",
       "        [1413., 1413., 1413., ..., 1410., 1398., 1398.],\n",
       "        [1413., 1413., 1413., ..., 1410., 1398., 1398.],\n",
       "        [1413., 1413., 1413., ..., 1410., 1398., 1398.]],\n",
       "\n",
       "       [[1256., 1285., 1410., ..., 1304., 1304., 1291.],\n",
       "        [1260., 1273., 1312., ..., 1292., 1286., 1286.],\n",
       "        [1279., 1282., 1310., ..., 1253., 1271., 1271.],\n",
       "        ...,\n",
       "        [1362., 1355., 1303., ..., 1319., 1298., 1296.],\n",
       "        [1225., 1256., 1241., ..., 1309., 1304., 1281.],\n",
       "        [1247., 1206., 1206., ..., 1288., 1301., 1265.]],\n",
       "\n",
       "       [[1234., 1249., 1426., ..., 1339., 1339., 1292.],\n",
       "        [1211., 1220., 1300., ..., 1346., 1266., 1266.],\n",
       "        [1216., 1239., 1293., ..., 1291., 1265., 1265.],\n",
       "        ...,\n",
       "        [1458., 1422., 1354., ..., 1368., 1352., 1375.],\n",
       "        [1236., 1274., 1253., ..., 1372., 1385., 1355.],\n",
       "        [1201., 1177., 1177., ..., 1359., 1376., 1326.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  18.,   20.,   20., ...,   18.,   18.,   18.],\n",
       "        [  18.,   20.,   20., ...,   18.,   18.,   18.],\n",
       "        [  18.,   20.,   20., ...,   18.,   18.,   18.],\n",
       "        ...,\n",
       "        [  19.,   19.,   19., ...,   21.,   22.,   22.],\n",
       "        [  19.,   19.,   19., ...,   21.,   22.,   22.],\n",
       "        [  19.,   19.,   19., ...,   21.,   22.,   22.]],\n",
       "\n",
       "       [[3725., 3763., 3763., ..., 3110., 3110., 3110.],\n",
       "        [3464., 3572., 3572., ..., 3110., 3110., 3110.],\n",
       "        [3464., 3572., 3572., ..., 3114., 3114., 3114.],\n",
       "        ...,\n",
       "        [3666., 3666., 3620., ..., 3329., 3337., 3337.],\n",
       "        [3402., 3402., 3371., ..., 3329., 3337., 3337.],\n",
       "        [3402., 3371., 3371., ..., 3337., 3375., 3375.]],\n",
       "\n",
       "       [[2929., 2986., 2986., ..., 2340., 2340., 2340.],\n",
       "        [2604., 2680., 2680., ..., 2340., 2340., 2340.],\n",
       "        [2604., 2680., 2680., ..., 2311., 2311., 2311.],\n",
       "        ...,\n",
       "        [2771., 2771., 2693., ..., 2442., 2420., 2420.],\n",
       "        [2527., 2527., 2475., ..., 2442., 2420., 2420.],\n",
       "        [2527., 2475., 2475., ..., 2414., 2434., 2434.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = base_transform(np.moveaxis(s1, 0, -1))\n",
    "s2 = base_transform(np.moveaxis(s2, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10.0264,  9.7807, 10.1396,  ..., 11.1320, 10.4918, 11.3751],\n",
       "         [10.7148,  9.8853,  9.2329,  ..., 10.4838, 10.7952, 11.7538],\n",
       "         [10.9224, 10.8413,  9.1965,  ..., 10.6194, 10.5045, 11.1630],\n",
       "         ...,\n",
       "         [ 9.5274,  9.6764,  9.8971,  ...,  9.5775, 10.1230, 10.3189],\n",
       "         [ 9.5317, 10.2360,  9.7651,  ..., 10.1221, 10.6615, 10.8344],\n",
       "         [10.2867,  9.9772, 10.8665,  ...,  9.8133, 10.4886, 11.1493]],\n",
       "\n",
       "        [[ 4.0023,  5.4672,  6.5442,  ...,  5.2685,  4.5779,  5.7610],\n",
       "         [ 5.2481,  5.0139,  5.4305,  ...,  3.7093,  4.7211,  5.3438],\n",
       "         [ 5.0670,  6.8875,  4.6819,  ...,  4.5337,  4.9847,  5.6762],\n",
       "         ...,\n",
       "         [ 3.8321,  3.9372,  5.4617,  ...,  4.5156,  4.3102,  5.3107],\n",
       "         [ 3.7988,  4.4828,  3.7054,  ...,  3.9380,  5.2030,  4.6722],\n",
       "         [ 2.4013,  3.0792,  2.5382,  ...,  3.5661,  4.0790,  4.2157]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1467., 1671., 1671.,  ..., 1397., 1397., 1397.],\n",
       "         [1467., 1671., 1671.,  ..., 1397., 1397., 1397.],\n",
       "         [1467., 1671., 1671.,  ..., 1397., 1397., 1397.],\n",
       "         ...,\n",
       "         [1413., 1413., 1413.,  ..., 1410., 1398., 1398.],\n",
       "         [1413., 1413., 1413.,  ..., 1410., 1398., 1398.],\n",
       "         [1413., 1413., 1413.,  ..., 1410., 1398., 1398.]],\n",
       "\n",
       "        [[1256., 1285., 1410.,  ..., 1304., 1304., 1291.],\n",
       "         [1260., 1273., 1312.,  ..., 1292., 1286., 1286.],\n",
       "         [1279., 1282., 1310.,  ..., 1253., 1271., 1271.],\n",
       "         ...,\n",
       "         [1362., 1355., 1303.,  ..., 1319., 1298., 1296.],\n",
       "         [1225., 1256., 1241.,  ..., 1309., 1304., 1281.],\n",
       "         [1247., 1206., 1206.,  ..., 1288., 1301., 1265.]],\n",
       "\n",
       "        [[1234., 1249., 1426.,  ..., 1339., 1339., 1292.],\n",
       "         [1211., 1220., 1300.,  ..., 1346., 1266., 1266.],\n",
       "         [1216., 1239., 1293.,  ..., 1291., 1265., 1265.],\n",
       "         ...,\n",
       "         [1458., 1422., 1354.,  ..., 1368., 1352., 1375.],\n",
       "         [1236., 1274., 1253.,  ..., 1372., 1385., 1355.],\n",
       "         [1201., 1177., 1177.,  ..., 1359., 1376., 1326.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  18.,   20.,   20.,  ...,   18.,   18.,   18.],\n",
       "         [  18.,   20.,   20.,  ...,   18.,   18.,   18.],\n",
       "         [  18.,   20.,   20.,  ...,   18.,   18.,   18.],\n",
       "         ...,\n",
       "         [  19.,   19.,   19.,  ...,   21.,   22.,   22.],\n",
       "         [  19.,   19.,   19.,  ...,   21.,   22.,   22.],\n",
       "         [  19.,   19.,   19.,  ...,   21.,   22.,   22.]],\n",
       "\n",
       "        [[3725., 3763., 3763.,  ..., 3110., 3110., 3110.],\n",
       "         [3464., 3572., 3572.,  ..., 3110., 3110., 3110.],\n",
       "         [3464., 3572., 3572.,  ..., 3114., 3114., 3114.],\n",
       "         ...,\n",
       "         [3666., 3666., 3620.,  ..., 3329., 3337., 3337.],\n",
       "         [3402., 3402., 3371.,  ..., 3329., 3337., 3337.],\n",
       "         [3402., 3371., 3371.,  ..., 3337., 3375., 3375.]],\n",
       "\n",
       "        [[2929., 2986., 2986.,  ..., 2340., 2340., 2340.],\n",
       "         [2604., 2680., 2680.,  ..., 2340., 2340., 2340.],\n",
       "         [2604., 2680., 2680.,  ..., 2311., 2311., 2311.],\n",
       "         ...,\n",
       "         [2771., 2771., 2693.,  ..., 2442., 2420., 2420.],\n",
       "         [2527., 2527., 2475.,  ..., 2442., 2420., 2420.],\n",
       "         [2527., 2475., 2475.,  ..., 2414., 2434., 2434.]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798],\n",
       "         [22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798],\n",
       "         [22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798],\n",
       "         ...,\n",
       "         [22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798],\n",
       "         [22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798],\n",
       "         [22.6798, 22.6798, 22.6798,  ..., 22.6798, 22.6798, 22.6798]],\n",
       "\n",
       "        [[14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390],\n",
       "         [14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390],\n",
       "         [14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390],\n",
       "         ...,\n",
       "         [14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390],\n",
       "         [14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390],\n",
       "         [14.9390, 14.9390, 14.9390,  ..., 14.9390, 14.9390, 14.9390]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize images channel wise\n",
    "s1_maxs = []\n",
    "for ch_idx in range(s1.shape[0]):\n",
    "    s1_maxs.append(\n",
    "        torch.ones((s1.shape[-2], s1.shape[-1])) * s1[ch_idx].max().item()\n",
    "        + 1e-5\n",
    "    )\n",
    "s1_maxs = torch.stack(s1_maxs)\n",
    "s1_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_maxs = []\n",
    "for b_idx in range(s2.shape[0]):\n",
    "    s2_maxs.append(\n",
    "        torch.ones((s2.shape[-2], s2.shape[-1])) * s2[b_idx].max().item() + 1e-5\n",
    "    )\n",
    "s2_maxs = torch.stack(s2_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalize:\n",
    "    s1 = s1 / s1_maxs\n",
    "    s2 = s2 / s2_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4421, 0.4313, 0.4471,  ..., 0.4908, 0.4626, 0.5016],\n",
       "         [0.4724, 0.4359, 0.4071,  ..., 0.4623, 0.4760, 0.5182],\n",
       "         [0.4816, 0.4780, 0.4055,  ..., 0.4682, 0.4632, 0.4922],\n",
       "         ...,\n",
       "         [0.4201, 0.4267, 0.4364,  ..., 0.4223, 0.4463, 0.4550],\n",
       "         [0.4203, 0.4513, 0.4306,  ..., 0.4463, 0.4701, 0.4777],\n",
       "         [0.4536, 0.4399, 0.4791,  ..., 0.4327, 0.4625, 0.4916]],\n",
       "\n",
       "        [[0.2679, 0.3660, 0.4381,  ..., 0.3527, 0.3064, 0.3856],\n",
       "         [0.3513, 0.3356, 0.3635,  ..., 0.2483, 0.3160, 0.3577],\n",
       "         [0.3392, 0.4610, 0.3134,  ..., 0.3035, 0.3337, 0.3800],\n",
       "         ...,\n",
       "         [0.2565, 0.2636, 0.3656,  ..., 0.3023, 0.2885, 0.3555],\n",
       "         [0.2543, 0.3001, 0.2480,  ..., 0.2636, 0.3483, 0.3128],\n",
       "         [0.1607, 0.2061, 0.1699,  ..., 0.2387, 0.2730, 0.2822]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "         [0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "         [0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "         ...,\n",
       "         [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993],\n",
       "         [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993],\n",
       "         [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993]],\n",
       "\n",
       "        [[0.5244, 0.5365, 0.5887,  ..., 0.5445, 0.5445, 0.5390],\n",
       "         [0.5261, 0.5315, 0.5478,  ..., 0.5395, 0.5370, 0.5370],\n",
       "         [0.5340, 0.5353, 0.5470,  ..., 0.5232, 0.5307, 0.5307],\n",
       "         ...,\n",
       "         [0.5687, 0.5658, 0.5441,  ..., 0.5507, 0.5420, 0.5411],\n",
       "         [0.5115, 0.5244, 0.5182,  ..., 0.5466, 0.5445, 0.5349],\n",
       "         [0.5207, 0.5035, 0.5035,  ..., 0.5378, 0.5432, 0.5282]],\n",
       "\n",
       "        [[0.4515, 0.4570, 0.5218,  ..., 0.4899, 0.4899, 0.4727],\n",
       "         [0.4431, 0.4464, 0.4757,  ..., 0.4925, 0.4632, 0.4632],\n",
       "         [0.4449, 0.4533, 0.4731,  ..., 0.4724, 0.4629, 0.4629],\n",
       "         ...,\n",
       "         [0.5335, 0.5203, 0.4954,  ..., 0.5005, 0.4947, 0.5031],\n",
       "         [0.4523, 0.4662, 0.4585,  ..., 0.5020, 0.5068, 0.4958],\n",
       "         [0.4394, 0.4307, 0.4307,  ..., 0.4973, 0.5035, 0.4852]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "         [0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "         [0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "         ...,\n",
       "         [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462],\n",
       "         [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462],\n",
       "         [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462]],\n",
       "\n",
       "        [[0.7963, 0.8044, 0.8044,  ..., 0.6648, 0.6648, 0.6648],\n",
       "         [0.7405, 0.7636, 0.7636,  ..., 0.6648, 0.6648, 0.6648],\n",
       "         [0.7405, 0.7636, 0.7636,  ..., 0.6657, 0.6657, 0.6657],\n",
       "         ...,\n",
       "         [0.7837, 0.7837, 0.7738,  ..., 0.7116, 0.7133, 0.7133],\n",
       "         [0.7272, 0.7272, 0.7206,  ..., 0.7116, 0.7133, 0.7133],\n",
       "         [0.7272, 0.7206, 0.7206,  ..., 0.7133, 0.7215, 0.7215]],\n",
       "\n",
       "        [[0.7626, 0.7774, 0.7774,  ..., 0.6092, 0.6092, 0.6092],\n",
       "         [0.6779, 0.6977, 0.6977,  ..., 0.6092, 0.6092, 0.6092],\n",
       "         [0.6779, 0.6977, 0.6977,  ..., 0.6017, 0.6017, 0.6017],\n",
       "         ...,\n",
       "         [0.7214, 0.7214, 0.7011,  ..., 0.6358, 0.6300, 0.6300],\n",
       "         [0.6579, 0.6579, 0.6444,  ..., 0.6358, 0.6300, 0.6300],\n",
       "         [0.6579, 0.6444, 0.6444,  ..., 0.6285, 0.6337, 0.6337]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"s1\": s1,\n",
    "    \"s2\": s2,\n",
    "    \"lc\": lc,\n",
    "    \"bounds\": bounds,\n",
    "    \"idx\": idx,\n",
    "    \"lc_label\": lc_label,\n",
    "    \"lc_label_str\": lc_label_str,\n",
    "    \"lc_multilabel\": lc_multilabel.numpy().tolist(),\n",
    "    \"lc_multilabel_one_hot\": lc_multilabel_one_hot,\n",
    "    \"season\": str(season.value),\n",
    "    \"scene\": obs.Scene,\n",
    "    \"id\": obs.ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s1': tensor([[[0.4421, 0.4313, 0.4471,  ..., 0.4908, 0.4626, 0.5016],\n",
       "          [0.4724, 0.4359, 0.4071,  ..., 0.4623, 0.4760, 0.5182],\n",
       "          [0.4816, 0.4780, 0.4055,  ..., 0.4682, 0.4632, 0.4922],\n",
       "          ...,\n",
       "          [0.4201, 0.4267, 0.4364,  ..., 0.4223, 0.4463, 0.4550],\n",
       "          [0.4203, 0.4513, 0.4306,  ..., 0.4463, 0.4701, 0.4777],\n",
       "          [0.4536, 0.4399, 0.4791,  ..., 0.4327, 0.4625, 0.4916]],\n",
       " \n",
       "         [[0.2679, 0.3660, 0.4381,  ..., 0.3527, 0.3064, 0.3856],\n",
       "          [0.3513, 0.3356, 0.3635,  ..., 0.2483, 0.3160, 0.3577],\n",
       "          [0.3392, 0.4610, 0.3134,  ..., 0.3035, 0.3337, 0.3800],\n",
       "          ...,\n",
       "          [0.2565, 0.2636, 0.3656,  ..., 0.3023, 0.2885, 0.3555],\n",
       "          [0.2543, 0.3001, 0.2480,  ..., 0.2636, 0.3483, 0.3128],\n",
       "          [0.1607, 0.2061, 0.1699,  ..., 0.2387, 0.2730, 0.2822]]],\n",
       "        dtype=torch.float64),\n",
       " 's2': tensor([[[0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "          [0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "          [0.8388, 0.9554, 0.9554,  ..., 0.7987, 0.7987, 0.7987],\n",
       "          ...,\n",
       "          [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993],\n",
       "          [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993],\n",
       "          [0.8079, 0.8079, 0.8079,  ..., 0.8062, 0.7993, 0.7993]],\n",
       " \n",
       "         [[0.5244, 0.5365, 0.5887,  ..., 0.5445, 0.5445, 0.5390],\n",
       "          [0.5261, 0.5315, 0.5478,  ..., 0.5395, 0.5370, 0.5370],\n",
       "          [0.5340, 0.5353, 0.5470,  ..., 0.5232, 0.5307, 0.5307],\n",
       "          ...,\n",
       "          [0.5687, 0.5658, 0.5441,  ..., 0.5507, 0.5420, 0.5411],\n",
       "          [0.5115, 0.5244, 0.5182,  ..., 0.5466, 0.5445, 0.5349],\n",
       "          [0.5207, 0.5035, 0.5035,  ..., 0.5378, 0.5432, 0.5282]],\n",
       " \n",
       "         [[0.4515, 0.4570, 0.5218,  ..., 0.4899, 0.4899, 0.4727],\n",
       "          [0.4431, 0.4464, 0.4757,  ..., 0.4925, 0.4632, 0.4632],\n",
       "          [0.4449, 0.4533, 0.4731,  ..., 0.4724, 0.4629, 0.4629],\n",
       "          ...,\n",
       "          [0.5335, 0.5203, 0.4954,  ..., 0.5005, 0.4947, 0.5031],\n",
       "          [0.4523, 0.4662, 0.4585,  ..., 0.5020, 0.5068, 0.4958],\n",
       "          [0.4394, 0.4307, 0.4307,  ..., 0.4973, 0.5035, 0.4852]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "          [0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "          [0.6923, 0.7692, 0.7692,  ..., 0.6923, 0.6923, 0.6923],\n",
       "          ...,\n",
       "          [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462],\n",
       "          [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462],\n",
       "          [0.7308, 0.7308, 0.7308,  ..., 0.8077, 0.8462, 0.8462]],\n",
       " \n",
       "         [[0.7963, 0.8044, 0.8044,  ..., 0.6648, 0.6648, 0.6648],\n",
       "          [0.7405, 0.7636, 0.7636,  ..., 0.6648, 0.6648, 0.6648],\n",
       "          [0.7405, 0.7636, 0.7636,  ..., 0.6657, 0.6657, 0.6657],\n",
       "          ...,\n",
       "          [0.7837, 0.7837, 0.7738,  ..., 0.7116, 0.7133, 0.7133],\n",
       "          [0.7272, 0.7272, 0.7206,  ..., 0.7116, 0.7133, 0.7133],\n",
       "          [0.7272, 0.7206, 0.7206,  ..., 0.7133, 0.7215, 0.7215]],\n",
       " \n",
       "         [[0.7626, 0.7774, 0.7774,  ..., 0.6092, 0.6092, 0.6092],\n",
       "          [0.6779, 0.6977, 0.6977,  ..., 0.6092, 0.6092, 0.6092],\n",
       "          [0.6779, 0.6977, 0.6977,  ..., 0.6017, 0.6017, 0.6017],\n",
       "          ...,\n",
       "          [0.7214, 0.7214, 0.7011,  ..., 0.6358, 0.6300, 0.6300],\n",
       "          [0.6579, 0.6579, 0.6444,  ..., 0.6358, 0.6300, 0.6300],\n",
       "          [0.6579, 0.6444, 0.6444,  ..., 0.6285, 0.6337, 0.6337]]],\n",
       "        dtype=torch.float64),\n",
       " 'lc': array([[[4, 4, 4, ..., 4, 4, 4],\n",
       "         [4, 4, 4, ..., 4, 4, 4],\n",
       "         [4, 4, 4, ..., 4, 4, 4],\n",
       "         ...,\n",
       "         [4, 4, 4, ..., 4, 4, 4],\n",
       "         [4, 4, 4, ..., 4, 4, 4],\n",
       "         [4, 4, 4, ..., 4, 4, 4]]]),\n",
       " 'bounds': BoundingBox(left=0.0, bottom=256.0, right=256.0, top=0.0),\n",
       " 'idx': 2,\n",
       " 'lc_label': 4,\n",
       " 'lc_label_str': 'Croplands',\n",
       " 'lc_multilabel': [4],\n",
       " 'lc_multilabel_one_hot': tensor([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " 'season': 'ROIs0000_test',\n",
       " 'scene': 0,\n",
       " 'id': 1101}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
